{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [05/May/2021 14:01:55] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [05/May/2021 14:02:17] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : Smart contracts are very popular nowadays. \n",
      "audio-chunks\\chunk2.wav : What are the problems they solve. \n",
      "audio-chunks\\chunk3.wav : Smart contract was first used by nexobio in 1997 long before bitcoin was created. \n",
      "audio-chunks\\chunk4.wav : Is a computer scientist lost colour and cryptographer to expire you his exact words that in simple terms you want to use a distributed ledger to store contract. \n",
      "audio-chunks\\chunk5.wav : No smart contracts or just like contracts in the real world. \n",
      "audio-chunks\\chunk6.wav : Difference is that they or completely digital. \n",
      "audio-chunks\\chunk7.wav : In fact smart contract is actually at any computer program that is stored inside of the burgeoning. \n",
      "audio-chunks\\chunk8.wav : What's the cover karen example to understand how smart contracts work. \n",
      "audio-chunks\\chunk9.wav : You probably are familiar with kickstarter the largest fundraising platform. \n",
      "audio-chunks\\chunk10.wav : Project team can go to text order via project sirf funding goal and start collecting money from others who believe in the idea. \n",
      "audio-chunks\\chunk11.wav : Kickstarter is a century a third party that sits between product teams and supporters. \n",
      "audio-chunks\\chunk12.wav : This means that both of them to trust text order to help other money correctly. \n",
      "audio-chunks\\chunk13.wav : The project was successfully funded the project team expect kickstarter to give them the money. \n",
      "audio-chunks\\chunk14.wav : Hand supporters wanted money to go to the project if it was funded. \n",
      "audio-chunks\\chunk15.wav : It has reached its goal. \n",
      "audio-chunks\\chunk16.wav : Both productive and a supporters have to trust kickstarter. \n",
      "audio-chunks\\chunk17.wav : Smart contracts which can be the similar system that doesn't require a tapori like its owner. \n",
      "audio-chunks\\chunk18.wav : Sumit trade smart contract with this. \n",
      "audio-chunks\\chunk19.wav : We can program smart contracts that holds all the receive funds and duster in goal is reached. \n",
      "audio-chunks\\chunk20.wav : What is a project cannot transfer the money to the smart contract. \n",
      "audio-chunks\\chunk21.wav : If the project gets fully funded the contract or manak with has the money to the creator of the project. \n",
      "audio-chunks\\chunk22.wav : Any project fails to meet this goes then the money automatically goes back to supporters. \n",
      "audio-chunks\\chunk23.wav : Indica smart contract are stored inside of watching everything is complete with distributed with this technique no one is in control of the money. \n",
      "audio-chunks\\chunk24.wav : Why should which was the smart contract. \n",
      "audio-chunks\\chunk25.wav : Babita smart contracts are stored on a blockchain the inherit some interesting properties. \n",
      "audio-chunks\\chunk26.wav : They are distributed. \n",
      "audio-chunks\\chunk27.wav : It's created a can never be changed the game. \n",
      "audio-chunks\\chunk28.wav : Suno go behind your back and have the code of a contract. \n",
      "audio-chunks\\chunk29.wav : Indian distributed output of a contract is validated by everyone on the never. \n",
      "audio-chunks\\chunk30.wav : Person cannot force the contract to release the funds because other people on the proposed part is it them and market as invalid. \n",
      "audio-chunks\\chunk31.wav : Jaipur in which ward contract becomes almost impossible. \n",
      "audio-chunks\\chunk32.wav : What contract can be applied to many different things pakistan crowdfunding. \n",
      "audio-chunks\\chunk33.wav : Banks for example could use it to issue means what to offer automatic payment. \n",
      "audio-chunks\\chunk34.wav : Insurance companies kit use it to process for mcqueen. \n",
      "audio-chunks\\chunk35.wav : The companies that use it for payment on delivery and so on its one. \n",
      "audio-chunks\\chunk36.wav : Tsunami my wonder where and how can i use smart contract. \n",
      "audio-chunks\\chunk37.wav : There are a handful box change to support smart contract. \n",
      "audio-chunks\\chunk38.wav : Biggest one is ethereum. \n",
      "audio-chunks\\chunk39.wav : Was specifically created and designed to support smart contract. \n",
      "audio-chunks\\chunk40.wav : Mount content can be programmed in special programming language call to delete this nike which was specifically created for yttrium and uses a syntax of resemble javascript. \n",
      "audio-chunks\\chunk41.wav : It's also worth noting that bitcoin also has support for smart contracts of the vessel limited compares with theory. \n"
     ]
    }
   ],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "import speech_recognition as sr \n",
    "import os \n",
    "import pydub\n",
    "import pyaudio\n",
    "import wave\n",
    "import pyttsx3\n",
    "pydub.AudioSegment.converter = r\"C:\\\\path\\\\to\\\\ffmpeg.exe\"\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from flask import *\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def upload():            \n",
    "    return render_template(\"file.html\")\n",
    "@app.route('/record', methods=['POST'])\n",
    "def record():\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 2\n",
    "    fs = 44100  # Record at 44100 samples per second\n",
    "    seconds = 120\n",
    "    filename = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    print('Recording')\n",
    "\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "\n",
    "    print('Finished recording')\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    sound = AudioSegment.from_wav(filename)  \n",
    "    r = sr.Recognizer()\n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "    # experiment with this value for your target audio file\n",
    "    min_silence_len = 600,\n",
    "    # adjust this per requirement\n",
    "    silence_thresh = sound.dBFS-16,\n",
    "    # keep the silence for 1 second, adjustable as well\n",
    "    keep_silence=400,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "    # export audio chunk and save it in\n",
    "    # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            r.adjust_for_ambient_noise(source,0.3)\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    stopWords = set(stopwords.words(\"english\")) \n",
    "    words = word_tokenize(whole_text) \n",
    "    freqTable = dict() \n",
    "    for word in words: \n",
    "        word = word.lower() \n",
    "        if word in stopWords: \n",
    "            continue\n",
    "        if word in freqTable: \n",
    "            freqTable[word] += 1\n",
    "        else: \n",
    "            freqTable[word] = 1\n",
    "    sentences = sent_tokenize(whole_text) \n",
    "    sentenceValue = dict() \n",
    "    for sentence in sentences: \n",
    "        for word, freq in freqTable.items(): \n",
    "            if word in sentence.lower(): \n",
    "                if sentence in sentenceValue: \n",
    "                    sentenceValue[sentence] += freq \n",
    "                else: \n",
    "                    sentenceValue[sentence] = freq \n",
    "    sumValues = 0\n",
    "    summary=''\n",
    "    for sentence in sentenceValue: \n",
    "        sumValues += sentenceValue[sentence] \n",
    "    average = int(sumValues / len(sentenceValue)) \n",
    "    for sentence in sentences: \n",
    "        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): \n",
    "            summary += \" \" + sentence\n",
    "    print(summary)\n",
    "    text_file = open(\"sample.txt\", \"w\")\n",
    "    text_file.write(summary)\n",
    "    return render_template(\"summary.html\", name=summary)\n",
    "@app.route('/success', methods=['POST'])\n",
    "def summary():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        f.save(f.filename)\n",
    "        sound = AudioSegment.from_wav(f.filename)  \n",
    "        r = sr.Recognizer()\n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "        chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 600,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-16,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=400,\n",
    "        )\n",
    "        folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "        if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "        whole_text = \"\"\n",
    "    # process each chunk \n",
    "        for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "            chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "            audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "            with sr.AudioFile(chunk_filename) as source:\n",
    "                r.adjust_for_ambient_noise(source,0.3)\n",
    "                audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "                try:\n",
    "                    text = r.recognize_google(audio_listened)\n",
    "                except sr.UnknownValueError as e:\n",
    "                    print(\"Error:\", str(e))\n",
    "                else:\n",
    "                    text = f\"{text.capitalize()}. \"\n",
    "                    print(chunk_filename, \":\", text)\n",
    "                    whole_text += text\n",
    "        stopWords = set(stopwords.words(\"english\")) \n",
    "        words = word_tokenize(whole_text) \n",
    "        freqTable = dict() \n",
    "        for word in words: \n",
    "            word = word.lower() \n",
    "            if word in stopWords: \n",
    "                continue\n",
    "            if word in freqTable: \n",
    "                freqTable[word] += 1\n",
    "            else: \n",
    "                freqTable[word] = 1\n",
    "        sentences = sent_tokenize(whole_text) \n",
    "        sentenceValue = dict() \n",
    "        for sentence in sentences: \n",
    "            for word, freq in freqTable.items(): \n",
    "                if word in sentence.lower(): \n",
    "                    if sentence in sentenceValue: \n",
    "                        sentenceValue[sentence] += freq \n",
    "                    else: \n",
    "                        sentenceValue[sentence] = freq \n",
    "        sumValues = 0\n",
    "        summary=''\n",
    "        for sentence in sentenceValue: \n",
    "            sumValues += sentenceValue[sentence] \n",
    "        average = int(sumValues / len(sentenceValue)) \n",
    "        for sentence in sentences: \n",
    "            if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)): \n",
    "                summary += \" \" + sentence\n",
    "        text_file = open(\"sample.txt\", \"w\")\n",
    "        text_file.write(summary)\n",
    "        return render_template(\"summary.html\", name=summary)\n",
    "@app.route('/contact', methods=['POST'])\n",
    "def Audio():\n",
    "    f = open(\"sample.txt\", \"r\")\n",
    "    ans=f.read()\n",
    "    engine = pyttsx3.init()\n",
    "    #get the voices of the driver\n",
    "    voice=engine.getProperty('voices')\n",
    "    #choose a voice and set it\n",
    "    engine.setProperty('voice',voice[1].id)\n",
    "    #set the volume incusive from 0.0 to 1.0\n",
    "    engine.setProperty('volume',1)\n",
    "    #set the rate of the speech\n",
    "    engine.setProperty('rate',178)\n",
    "    #summary audio is generated\n",
    "    engine.say(ans)\n",
    "    engine.runAndWait()\n",
    "    return render_template(\"Audio.html\")\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
